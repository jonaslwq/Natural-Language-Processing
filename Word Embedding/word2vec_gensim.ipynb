{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conceptual-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "still-saver",
   "metadata": {},
   "source": [
    "### Reading and Exploring the Dataset\n",
    "The dataset we are using here is a subset of Amazon reviews from the Sports & Outdoors category. The data is stored as a JSON file and can be read using pandas.\n",
    "\n",
    "Link to the Dataset: http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Sports_and_Outdoors_5.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "residential-people",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIXZKN4ACSKI</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>David Briner</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This came in on time and I am veru happy with ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Woks very good</td>\n",
       "      <td>1390694400</td>\n",
       "      <td>01 26, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1L5P841VIO02V</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>Jason A. Kramer</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>I had a factory Glock tool that I was using fo...</td>\n",
       "      <td>5</td>\n",
       "      <td>Works as well as the factory tool</td>\n",
       "      <td>1328140800</td>\n",
       "      <td>02 2, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AB2W04NI4OEAD</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>J. Fernald</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>If you don't have a 3/32 punch or would like t...</td>\n",
       "      <td>4</td>\n",
       "      <td>It's a punch, that's all.</td>\n",
       "      <td>1330387200</td>\n",
       "      <td>02 28, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A148SVSWKTJKU6</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>Jusitn A. Watts \"Maverick9614\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This works no better than any 3/32 punch you w...</td>\n",
       "      <td>4</td>\n",
       "      <td>It's a punch with a Glock logo.</td>\n",
       "      <td>1328400000</td>\n",
       "      <td>02 5, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAWJ6LW9WMOO</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>Material Man</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I purchased this thinking maybe I need a speci...</td>\n",
       "      <td>4</td>\n",
       "      <td>Ok,tool does what a regular punch does.</td>\n",
       "      <td>1366675200</td>\n",
       "      <td>04 23, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                    reviewerName helpful  \\\n",
       "0    AIXZKN4ACSKI  1881509818                    David Briner  [0, 0]   \n",
       "1  A1L5P841VIO02V  1881509818                 Jason A. Kramer  [1, 1]   \n",
       "2   AB2W04NI4OEAD  1881509818                      J. Fernald  [2, 2]   \n",
       "3  A148SVSWKTJKU6  1881509818  Jusitn A. Watts \"Maverick9614\"  [0, 0]   \n",
       "4   AAAWJ6LW9WMOO  1881509818                    Material Man  [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  This came in on time and I am veru happy with ...        5   \n",
       "1  I had a factory Glock tool that I was using fo...        5   \n",
       "2  If you don't have a 3/32 punch or would like t...        4   \n",
       "3  This works no better than any 3/32 punch you w...        4   \n",
       "4  I purchased this thinking maybe I need a speci...        4   \n",
       "\n",
       "                                   summary  unixReviewTime   reviewTime  \n",
       "0                           Woks very good      1390694400  01 26, 2014  \n",
       "1        Works as well as the factory tool      1328140800   02 2, 2012  \n",
       "2                It's a punch, that's all.      1330387200  02 28, 2012  \n",
       "3          It's a punch with a Glock logo.      1328400000   02 5, 2012  \n",
       "4  Ok,tool does what a regular punch does.      1366675200  04 23, 2013  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(r\"C:\\Users\\jonas\\OneDrive\\Desktop\\Work\\Coding\\NLP\\Data\\Sports_and_Outdoors_5.json\", lines=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "parliamentary-relations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296337, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "sensitive-peoples",
   "metadata": {},
   "source": [
    "### Simple Preprocessing & Tokenization\n",
    "The first thing to do for any data science task is to clean the data.\n",
    "For NLP, we apply various processing like converting all the words to lower case, trimming spaces, removing punctuations. \n",
    "This is something we will do over here too.\n",
    "\n",
    "Additionally, we can also remove stop words like 'and', 'or', 'is', 'the', 'a', 'an' and convert words to their root forms like 'running' to 'run'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "informational-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = df.reviewText.apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "flush-courtesy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [this, came, in, on, time, and, am, veru, happ...\n",
       "1         [had, factory, glock, tool, that, was, using, ...\n",
       "2         [if, you, don, have, punch, or, would, like, t...\n",
       "3         [this, works, no, better, than, any, punch, yo...\n",
       "4         [purchased, this, thinking, maybe, need, speci...\n",
       "                                ...                        \n",
       "296332    [this, is, water, bottle, done, right, it, is,...\n",
       "296333    [if, you, re, looking, for, an, insulated, wat...\n",
       "296334    [this, hydracentials, sporty, oz, double, insu...\n",
       "296335    [as, usual, received, this, item, free, in, ex...\n",
       "296336    [hydracentials, insulated, oz, water, bottle, ...\n",
       "Name: reviewText, Length: 296337, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "engaging-yorkshire",
   "metadata": {},
   "source": [
    "### Training the Word2Vec Model\n",
    "\n",
    "Train the model for reviews. Use a window of size 10 i.e. 10 words before the present word and 10 words ahead. A sentence with at least 2 words should only be considered, configure this using min_count parameter.\n",
    "\n",
    "Workers define how many CPU threads to be used."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "civic-links",
   "metadata": {},
   "source": [
    "#### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "determined-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "olympic-manner",
   "metadata": {},
   "source": [
    "#### Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "juvenile-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(review_text, progress_per=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "pharmaceutical-adoption",
   "metadata": {},
   "source": [
    "#### Train the Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "adopted-kentucky",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91343193, 121496535)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "creative-convert",
   "metadata": {},
   "source": [
    "### Finding Similar Words and Similarity between words\n",
    "https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "legislative-bearing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"apple\"].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f9461c8",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72539919",
   "metadata": {},
   "source": [
    "Turn all individual words into vector and sum all of them up into a single vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "709b3095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def text_to_vector(text):\n",
    "    # Split the text into tokens\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Initialize an empty vector\n",
    "    vector = np.zeros(model.vector_size)\n",
    "    \n",
    "    # Iterate over each token and add its corresponding word vector\n",
    "    for token in tokens:\n",
    "        if token in model.wv:\n",
    "            vector += model.wv[token]\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1ce21d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"vector\"] = df[\"reviewText\"].apply(text_to_vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03c42c2b",
   "metadata": {},
   "source": [
    "Resample the distribution size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ca4027c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    188208\n",
       "4     64809\n",
       "3     24071\n",
       "2     10204\n",
       "1      9045\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ce4b164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9045\n",
       "2    9045\n",
       "3    9045\n",
       "4    9045\n",
       "5    9045\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_samples = 9045\n",
    "\n",
    "\n",
    "df_1 = df[df.overall==1].sample(min_samples, random_state=2022)\n",
    "df_2 = df[df.overall==2].sample(min_samples, random_state=2022)\n",
    "df_3 = df[df.overall==3].sample(min_samples, random_state=2022)\n",
    "df_4 = df[df.overall==4].sample(min_samples, random_state=2022)\n",
    "df_5 = df[df.overall==5].sample(min_samples, random_state=2022)\n",
    "\n",
    "df_balanced = pd.concat([df_1, df_2, df_3, df_4, df_5],axis=0)\n",
    "df_balanced.overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65bdac4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91191</th>\n",
       "      <td>AYY4PYXVRKJ7D</td>\n",
       "      <td>B00152R8Q6</td>\n",
       "      <td>Marty J. Leake \"Marty Leake\"</td>\n",
       "      <td>[0, 5]</td>\n",
       "      <td>The spikes on my bicycle wasn't compatible. I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>It didn't work for my bike</td>\n",
       "      <td>1370044800</td>\n",
       "      <td>06 1, 2013</td>\n",
       "      <td>[-8.227951467037201, 22.20028881728649, 14.223...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69259</th>\n",
       "      <td>A2XT3Q4KMMR6R</td>\n",
       "      <td>B000R4HSW2</td>\n",
       "      <td>OmLord</td>\n",
       "      <td>[0, 4]</td>\n",
       "      <td>I have never before been so utterly disappoint...</td>\n",
       "      <td>1</td>\n",
       "      <td>I hate this item!!!!!!</td>\n",
       "      <td>1380758400</td>\n",
       "      <td>10 3, 2013</td>\n",
       "      <td>[1.0154871715931222, -28.47037695394829, 18.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263662</th>\n",
       "      <td>A1I601AN1HJEXP</td>\n",
       "      <td>B007XFORCC</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>[3, 5]</td>\n",
       "      <td>I ordered two of these items, from two differe...</td>\n",
       "      <td>1</td>\n",
       "      <td>Product quit working immediately</td>\n",
       "      <td>1367452800</td>\n",
       "      <td>05 2, 2013</td>\n",
       "      <td>[-23.494620902463794, -2.9773764219135046, 7.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132166</th>\n",
       "      <td>A3EK5DN2JDH7AK</td>\n",
       "      <td>B001MYGM5A</td>\n",
       "      <td>Zorro</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I returned mine. I wanted something a bit heav...</td>\n",
       "      <td>1</td>\n",
       "      <td>Not too sturdy</td>\n",
       "      <td>1396396800</td>\n",
       "      <td>04 2, 2014</td>\n",
       "      <td>[10.416978031396866, 2.1522437827661633, -8.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19746</th>\n",
       "      <td>A1Z7OL22XV3JT8</td>\n",
       "      <td>B0009PUQ8M</td>\n",
       "      <td>D. Evans</td>\n",
       "      <td>[7, 8]</td>\n",
       "      <td>buy yourself a mallot and a small dust broom/p...</td>\n",
       "      <td>1</td>\n",
       "      <td>Not really worth it</td>\n",
       "      <td>1247097600</td>\n",
       "      <td>07 9, 2009</td>\n",
       "      <td>[4.26598484069109, 11.463842380791903, 7.08866...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID        asin                  reviewerName helpful  \\\n",
       "91191    AYY4PYXVRKJ7D  B00152R8Q6  Marty J. Leake \"Marty Leake\"  [0, 5]   \n",
       "69259    A2XT3Q4KMMR6R  B000R4HSW2                        OmLord  [0, 4]   \n",
       "263662  A1I601AN1HJEXP  B007XFORCC               Amazon Customer  [3, 5]   \n",
       "132166  A3EK5DN2JDH7AK  B001MYGM5A                         Zorro  [0, 0]   \n",
       "19746   A1Z7OL22XV3JT8  B0009PUQ8M                      D. Evans  [7, 8]   \n",
       "\n",
       "                                               reviewText  overall  \\\n",
       "91191   The spikes on my bicycle wasn't compatible. I ...        1   \n",
       "69259   I have never before been so utterly disappoint...        1   \n",
       "263662  I ordered two of these items, from two differe...        1   \n",
       "132166  I returned mine. I wanted something a bit heav...        1   \n",
       "19746   buy yourself a mallot and a small dust broom/p...        1   \n",
       "\n",
       "                                 summary  unixReviewTime  reviewTime  \\\n",
       "91191         It didn't work for my bike      1370044800  06 1, 2013   \n",
       "69259             I hate this item!!!!!!      1380758400  10 3, 2013   \n",
       "263662  Product quit working immediately      1367452800  05 2, 2013   \n",
       "132166                    Not too sturdy      1396396800  04 2, 2014   \n",
       "19746                Not really worth it      1247097600  07 9, 2009   \n",
       "\n",
       "                                                   vector  \n",
       "91191   [-8.227951467037201, 22.20028881728649, 14.223...  \n",
       "69259   [1.0154871715931222, -28.47037695394829, 18.41...  \n",
       "263662  [-23.494620902463794, -2.9773764219135046, 7.2...  \n",
       "132166  [10.416978031396866, 2.1522437827661633, -8.03...  \n",
       "19746   [4.26598484069109, 11.463842380791903, 7.08866...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6416ea2d",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2896dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_balanced[\"vector\"].values,\n",
    "    df_balanced[\"overall\"],\n",
    "    random_state=2022,\n",
    "    stratify = df_balanced[\"overall\"],\n",
    "    test_size=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d6c83227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36180, 100)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d = np.stack(X_test)\n",
    "\n",
    "X_train_2d.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0019f7f4",
   "metadata": {},
   "source": [
    "Building different ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9b850d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "#doing scaling because Negative values will not pass into Naive Bayes models\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train = scaler.fit_transform(X_train_2d)\n",
    "scaled_test = scaler.transform(X_test_2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.49      0.40      1809\n",
      "           2       0.25      0.26      0.25      1809\n",
      "           3       0.26      0.26      0.26      1809\n",
      "           4       0.26      0.21      0.23      1809\n",
      "           5       0.45      0.30      0.36      1809\n",
      "\n",
      "    accuracy                           0.31      9045\n",
      "   macro avg       0.31      0.31      0.30      9045\n",
      "weighted avg       0.31      0.31      0.30      9045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "#1. creating a KNN model object\n",
    "knnCLF = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "knnCLF.fit(scaled_train, y_train)\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = knnCLF.predict(scaled_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "94ee26ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.52      0.46      1809\n",
      "           2       0.30      0.25      0.27      1809\n",
      "           3       0.29      0.28      0.29      1809\n",
      "           4       0.29      0.23      0.25      1809\n",
      "           5       0.46      0.51      0.48      1809\n",
      "\n",
      "    accuracy                           0.36      9045\n",
      "   macro avg       0.35      0.36      0.35      9045\n",
      "weighted avg       0.35      0.36      0.35      9045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "#1. creating a Random Forest model object\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "clf.fit(scaled_train, y_train)\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = clf.predict(scaled_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6cdc5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.52      0.47      2261\n",
      "           2       0.31      0.26      0.29      2262\n",
      "           3       0.32      0.31      0.31      2261\n",
      "           4       0.33      0.26      0.29      2261\n",
      "           5       0.48      0.55      0.51      2262\n",
      "\n",
      "    accuracy                           0.38     11307\n",
      "   macro avg       0.37      0.38      0.38     11307\n",
      "weighted avg       0.37      0.38      0.38     11307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "#1. creating a GradientBoosting model object\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "clf.fit(scaled_train, y_train)\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = clf.predict(scaled_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63c1bf34",
   "metadata": {},
   "source": [
    "Adding weight to each word using TF-IDF before summing them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e103988",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_vectors = vectorizer.fit_transform(df_balanced[\"reviewText\"])\n",
    "\n",
    "df_balanced[\"vector_id\"] = [np.sum([model.wv[token] * tfidf_vectors[i, vectorizer.vocabulary_[token]]\n",
    "                       for token in text.split() if token in model.wv], axis=0)\n",
    "               for i, text in enumerate(df_balanced[\"reviewText\"])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ea5b812",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de866167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_balanced[\"vector_id\"],\n",
    "    df_balanced[\"overall\"],\n",
    "    random_state=2022,\n",
    "    stratify = df_balanced[\"overall\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55b1748a",
   "metadata": {},
   "source": [
    "Training the different ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47d99535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.51      0.41      2261\n",
      "           2       0.24      0.25      0.25      2262\n",
      "           3       0.24      0.25      0.24      2261\n",
      "           4       0.27      0.23      0.25      2261\n",
      "           5       0.46      0.28      0.35      2262\n",
      "\n",
      "    accuracy                           0.30     11307\n",
      "   macro avg       0.31      0.30      0.30     11307\n",
      "weighted avg       0.31      0.30      0.30     11307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. creating a KNN model object\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "model.fit(X_train_2d, y_train)\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = model.predict(X_test_2d)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cdcceeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.50      0.45      2261\n",
      "           2       0.27      0.24      0.25      2262\n",
      "           3       0.29      0.29      0.29      2261\n",
      "           4       0.30      0.24      0.27      2261\n",
      "           5       0.46      0.51      0.49      2262\n",
      "\n",
      "    accuracy                           0.36     11307\n",
      "   macro avg       0.35      0.36      0.35     11307\n",
      "weighted avg       0.35      0.36      0.35     11307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. creating a Random Forest model object\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "model.fit(X_train_2d, y_train)\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = model.predict(X_test_2d)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec356a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.52      0.46      2261\n",
      "           2       0.30      0.26      0.28      2262\n",
      "           3       0.32      0.30      0.31      2261\n",
      "           4       0.33      0.27      0.29      2261\n",
      "           5       0.47      0.55      0.51      2262\n",
      "\n",
      "    accuracy                           0.38     11307\n",
      "   macro avg       0.37      0.38      0.37     11307\n",
      "weighted avg       0.37      0.38      0.37     11307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. creating a GradientBoosting model object\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "model.fit(X_train_2d, y_train)\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = model.predict(X_test_2d)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4871f258",
   "metadata": {},
   "source": [
    "Using google news api and mean Word2Vec instead of sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "59e11a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------------------------------] 0.4% 6.0/1662.8MB downloaded"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jonas\\OneDrive\\Desktop\\Work\\Coding\\NLP\\MachineLearning\\NLP\\Word Embedding\\word2vec_gensim.ipynb Cell 42\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jonas/OneDrive/Desktop/Work/Coding/NLP/MachineLearning/NLP/Word%20Embedding/word2vec_gensim.ipynb#Y101sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdownloader\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mapi\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jonas/OneDrive/Desktop/Work/Coding/NLP/MachineLearning/NLP/Word%20Embedding/word2vec_gensim.ipynb#Y101sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m wv \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mword2vec-google-news-300\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\gensim\\downloader.py:496\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, return_path)\u001b[0m\n\u001b[0;32m    494\u001b[0m path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(folder_dir, file_name)\n\u001b[0;32m    495\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(folder_dir):\n\u001b[1;32m--> 496\u001b[0m     _download(name)\n\u001b[0;32m    498\u001b[0m \u001b[39mif\u001b[39;00m return_path:\n\u001b[0;32m    499\u001b[0m     \u001b[39mreturn\u001b[39;00m path\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\gensim\\downloader.py:396\u001b[0m, in \u001b[0;36m_download\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    394\u001b[0m fname \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{fname}\u001b[39;00m\u001b[39m.gz\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(fname\u001b[39m=\u001b[39mname)\n\u001b[0;32m    395\u001b[0m dst_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(tmp_dir, fname)\n\u001b[1;32m--> 396\u001b[0m urllib\u001b[39m.\u001b[39;49murlretrieve(url_data, dst_path, reporthook\u001b[39m=\u001b[39;49m_progress)\n\u001b[0;32m    397\u001b[0m \u001b[39mif\u001b[39;00m _calculate_md5_checksum(dst_path) \u001b[39m==\u001b[39m _get_checksum(name):\n\u001b[0;32m    398\u001b[0m     sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\urllib\\request.py:275\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    273\u001b[0m             blocknum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    274\u001b[0m             \u001b[39mif\u001b[39;00m reporthook:\n\u001b[1;32m--> 275\u001b[0m                 reporthook(blocknum, bs, size)\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m size \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m read \u001b[39m<\u001b[39m size:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m ContentTooShortError(\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mretrieval incomplete: got only \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m out of \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m bytes\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m%\u001b[39m (read, size), result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\gensim\\downloader.py:123\u001b[0m, in \u001b[0;36m_progress\u001b[1;34m(chunks_downloaded, chunk_size, total_size, part, total_parts)\u001b[0m\n\u001b[0;32m    121\u001b[0m bar \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m filled_len \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m (bar_len \u001b[39m-\u001b[39m filled_len)\n\u001b[0;32m    122\u001b[0m \u001b[39mif\u001b[39;00m total_parts \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 123\u001b[0m     sys\u001b[39m.\u001b[39;49mstdout\u001b[39m.\u001b[39;49mwrite(\n\u001b[0;32m    124\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39m\\r\u001b[39;49;00m\u001b[39m[\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m] \u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m%s\u001b[39;49;00m\u001b[39m \u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39mMB downloaded\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m%\u001b[39;49m (\n\u001b[0;32m    125\u001b[0m             bar, percent_downloaded, \u001b[39m\"\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    126\u001b[0m             \u001b[39mround\u001b[39;49m(size_downloaded \u001b[39m/\u001b[39;49m (\u001b[39m1024\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39m1024\u001b[39;49m), \u001b[39m1\u001b[39;49m),\n\u001b[0;32m    127\u001b[0m             \u001b[39mround\u001b[39;49m(\u001b[39mfloat\u001b[39;49m(total_size) \u001b[39m/\u001b[39;49m (\u001b[39m1024\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39m1024\u001b[39;49m), \u001b[39m1\u001b[39;49m))\n\u001b[0;32m    128\u001b[0m     )\n\u001b[0;32m    129\u001b[0m     sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mflush()\n\u001b[0;32m    130\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\ipykernel\\iostream.py:555\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpub_thread\u001b[39m.\u001b[39mschedule(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flush)\n\u001b[0;32m    554\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 555\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_schedule_flush()\n\u001b[0;32m    557\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(string)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\ipykernel\\iostream.py:461\u001b[0m, in \u001b[0;36mOutStream._schedule_flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_schedule_in_thread\u001b[39m():\n\u001b[0;32m    459\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_io_loop\u001b[39m.\u001b[39mcall_later(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflush_interval, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flush)\n\u001b[1;32m--> 461\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpub_thread\u001b[39m.\u001b[39;49mschedule(_schedule_in_thread)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\ipykernel\\iostream.py:210\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_events\u001b[39m.\u001b[39mappend(f)\n\u001b[0;32m    209\u001b[0m     \u001b[39m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event_pipe\u001b[39m.\u001b[39;49msend(\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    212\u001b[0m     f()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\zmq\\sugar\\socket.py:620\u001b[0m, in \u001b[0;36mSocket.send\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    613\u001b[0m         data \u001b[39m=\u001b[39m zmq\u001b[39m.\u001b[39mFrame(\n\u001b[0;32m    614\u001b[0m             data,\n\u001b[0;32m    615\u001b[0m             track\u001b[39m=\u001b[39mtrack,\n\u001b[0;32m    616\u001b[0m             copy\u001b[39m=\u001b[39mcopy \u001b[39mor\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    617\u001b[0m             copy_threshold\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy_threshold,\n\u001b[0;32m    618\u001b[0m         )\n\u001b[0;32m    619\u001b[0m     data\u001b[39m.\u001b[39mgroup \u001b[39m=\u001b[39m group\n\u001b[1;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(data, flags\u001b[39m=\u001b[39;49mflags, copy\u001b[39m=\u001b[39;49mcopy, track\u001b[39m=\u001b[39;49mtrack)\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:746\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:793\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\backend\\cython\\socket.pyx:250\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "04043ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIXZKN4ACSKI</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>David Briner</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This came in on time and I am veru happy with ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Woks very good</td>\n",
       "      <td>1390694400</td>\n",
       "      <td>01 26, 2014</td>\n",
       "      <td>[-22.2389500788413, 8.197773933410645, 10.2137...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1L5P841VIO02V</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>Jason A. Kramer</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>I had a factory Glock tool that I was using fo...</td>\n",
       "      <td>5</td>\n",
       "      <td>Works as well as the factory tool</td>\n",
       "      <td>1328140800</td>\n",
       "      <td>02 2, 2012</td>\n",
       "      <td>[-14.604479933157563, 4.497607171535492, 6.369...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AB2W04NI4OEAD</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>J. Fernald</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>If you don't have a 3/32 punch or would like t...</td>\n",
       "      <td>4</td>\n",
       "      <td>It's a punch, that's all.</td>\n",
       "      <td>1330387200</td>\n",
       "      <td>02 28, 2012</td>\n",
       "      <td>[21.604750588536263, -14.582560919225216, 8.98...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A148SVSWKTJKU6</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>Jusitn A. Watts \"Maverick9614\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This works no better than any 3/32 punch you w...</td>\n",
       "      <td>4</td>\n",
       "      <td>It's a punch with a Glock logo.</td>\n",
       "      <td>1328400000</td>\n",
       "      <td>02 5, 2012</td>\n",
       "      <td>[-3.0750463902950287, -30.545307585038245, 3.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAWJ6LW9WMOO</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>Material Man</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I purchased this thinking maybe I need a speci...</td>\n",
       "      <td>4</td>\n",
       "      <td>Ok,tool does what a regular punch does.</td>\n",
       "      <td>1366675200</td>\n",
       "      <td>04 23, 2013</td>\n",
       "      <td>[-4.436040550470352, 11.525207764469087, -9.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                    reviewerName helpful  \\\n",
       "0    AIXZKN4ACSKI  1881509818                    David Briner  [0, 0]   \n",
       "1  A1L5P841VIO02V  1881509818                 Jason A. Kramer  [1, 1]   \n",
       "2   AB2W04NI4OEAD  1881509818                      J. Fernald  [2, 2]   \n",
       "3  A148SVSWKTJKU6  1881509818  Jusitn A. Watts \"Maverick9614\"  [0, 0]   \n",
       "4   AAAWJ6LW9WMOO  1881509818                    Material Man  [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  This came in on time and I am veru happy with ...        5   \n",
       "1  I had a factory Glock tool that I was using fo...        5   \n",
       "2  If you don't have a 3/32 punch or would like t...        4   \n",
       "3  This works no better than any 3/32 punch you w...        4   \n",
       "4  I purchased this thinking maybe I need a speci...        4   \n",
       "\n",
       "                                   summary  unixReviewTime   reviewTime  \\\n",
       "0                           Woks very good      1390694400  01 26, 2014   \n",
       "1        Works as well as the factory tool      1328140800   02 2, 2012   \n",
       "2                It's a punch, that's all.      1330387200  02 28, 2012   \n",
       "3          It's a punch with a Glock logo.      1328400000   02 5, 2012   \n",
       "4  Ok,tool does what a regular punch does.      1366675200  04 23, 2013   \n",
       "\n",
       "                                              vector  \n",
       "0  [-22.2389500788413, 8.197773933410645, 10.2137...  \n",
       "1  [-14.604479933157563, 4.497607171535492, 6.369...  \n",
       "2  [21.604750588536263, -14.582560919225216, 8.98...  \n",
       "3  [-3.0750463902950287, -30.545307585038245, 3.6...  \n",
       "4  [-4.436040550470352, 11.525207764469087, -9.03...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "62ed52eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\") # if this fails then run \"python -m spacy download en_core_web_lg\" to download that model\n",
    "\n",
    "def preprocess_and_vectorize(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "        \n",
    "    return model.get_mean_vector(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9ff0a785",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Word2Vec' object has no attribute 'get_mean_vector'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jonas\\OneDrive\\Desktop\\Work\\Coding\\NLP\\MachineLearning\\NLP\\Word Embedding\\word2vec_gensim.ipynb Cell 45\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jonas/OneDrive/Desktop/Work/Coding/NLP/MachineLearning/NLP/Word%20Embedding/word2vec_gensim.ipynb#Y104sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mvector_mean\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mreviewText\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m text: preprocess_and_vectorize(text))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\series.py:4774\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4664\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4665\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4666\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4669\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4670\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4671\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4672\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4673\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4772\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4773\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4774\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\apply.py:1100\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1097\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1100\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\apply.py:1151\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1150\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1151\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1152\u001b[0m             values,\n\u001b[0;32m   1153\u001b[0m             f,\n\u001b[0;32m   1154\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1155\u001b[0m         )\n\u001b[0;32m   1157\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1158\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1159\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\_libs\\lib.pyx:2919\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jonas\\OneDrive\\Desktop\\Work\\Coding\\NLP\\MachineLearning\\NLP\\Word Embedding\\word2vec_gensim.ipynb Cell 45\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jonas/OneDrive/Desktop/Work/Coding/NLP/MachineLearning/NLP/Word%20Embedding/word2vec_gensim.ipynb#Y104sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mvector_mean\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mreviewText\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m text: preprocess_and_vectorize(text))\n",
      "\u001b[1;32mc:\\Users\\jonas\\OneDrive\\Desktop\\Work\\Coding\\NLP\\MachineLearning\\NLP\\Word Embedding\\word2vec_gensim.ipynb Cell 45\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jonas/OneDrive/Desktop/Work/Coding/NLP/MachineLearning/NLP/Word%20Embedding/word2vec_gensim.ipynb#Y104sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jonas/OneDrive/Desktop/Work/Coding/NLP/MachineLearning/NLP/Word%20Embedding/word2vec_gensim.ipynb#Y104sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     filtered_tokens\u001b[39m.\u001b[39mappend(token\u001b[39m.\u001b[39mlemma_)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jonas/OneDrive/Desktop/Work/Coding/NLP/MachineLearning/NLP/Word%20Embedding/word2vec_gensim.ipynb#Y104sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mget_mean_vector(filtered_tokens)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Word2Vec' object has no attribute 'get_mean_vector'"
     ]
    }
   ],
   "source": [
    "df['vector_mean'] = df['reviewText'].apply(lambda text: preprocess_and_vectorize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eb3e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.vector_mean.values, \n",
    "    df.overall, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2022,\n",
    "    stratify=df.overall\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2092d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_train before reshaping: \", X_train.shape)\n",
    "print(\"Shape of X_test before reshaping: \", X_test.shape)\n",
    "\n",
    "\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d =  np.stack(X_test)\n",
    "\n",
    "print(\"Shape of X_train after reshaping: \", X_train_2d.shape)\n",
    "print(\"Shape of X_test after reshaping: \", X_test_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a135d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#1. creating a GradientBoosting model object\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = clf.predict(X_test_2d)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
